{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas & BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TLDR;**\n",
    "\n",
    "- In this notebook we are going to see how we can combine two highly useful Python libraries: `pandas` and Beautifulsoup (BS).\n",
    "- To demonstrate this, we will write a Python program that **compute statistics** about the **frequency of names** found in a small set of EpiDoc TEI/XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup: a quick introduction\n",
    "\n",
    "There are several Python libraries to parse XML but `BeautifulSoup` is somehow the swiss knife of XML parsing.\n",
    "\n",
    "It can parse HTML, XML, as well as ill-formed or broken XML documents (very useful for legacy XML or even SGML data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open an XML file with BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/'\n",
    "\n",
    "# let's get the path of XML files\n",
    "# we filter only files with XML extension\n",
    "# it can be useful to ignore e.g. `.DS_Store` files (under MacOS)\n",
    "\n",
    "xml_files = [\n",
    "    os.path.join(data_folder, file)\n",
    "    for file in os.listdir(data_folder)\n",
    "    if \".xml\" in file\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not specifying the UTF-8 encoding of the XML files we are about the open\n",
    "# raises an exception on Win, while works fine on Unix systems,\n",
    "# see https://stackoverflow.com/questions/27092833/unicodeencodeerror-charmap-codec-cant-encode-characters\n",
    "with open(xml_files[0], 'r', encoding='utf-8') as inpfile:\n",
    "    xml_doc = BeautifulSoup(inpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding elements by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_element = xml_doc.find_all(\n",
    "    attrs={'xml:id': 'representation'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by definition, there should exist excatly one element\n",
    "# with a given ID within the same document\n",
    "assert len(target_element) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding elements by other attributes\n",
    "\n",
    "The same search logic applies to any XML attribute.\n",
    "\n",
    "Here we search for all `<name>` with `@type = patronymic`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_doc.find_all(\n",
    "    'name',\n",
    "    attrs={'type': 'patronymic'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding elements by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_doc.find_all(\n",
    "    'persname'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_doc.find_all(\n",
    "    'bibl'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the XML tree\n",
    "\n",
    "So far we have seen how to process all elements matching a given query, no matter where they are found in the document. But in other cases, it's desirable to navigate through the hierarchical structure of a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's navigate a bit the `edition` section of an EpiDoc TEI file. \n",
    "\n",
    "First off, we isolate this element, contained in a `<div>` with `@type=edition`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edition = xml_doc.find_all(\n",
    "    'div',\n",
    "    attrs={'type': 'edition'}\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in edition.children:\n",
    "    print(f\"Element type: {type(child)}, element name: {child.name}, element content: \\'{child}\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, persname in enumerate(edition.find_all('name')):\n",
    "    # note that element name and attribute name get lowercased\n",
    "    print(i + 1, persname.text.replace('\\n', ' '), persname.get('nymref'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(persname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML data → `DataFrame`\n",
    "\n",
    "**Why?**\n",
    "\n",
    "When working with data, it's often very useful to compute some statistics about them. If you are working with a corpus of texts encoded it TEI/XML, you'll have to extract information from the XML files to be able to compute the stats.\n",
    "\n",
    "**How?**\n",
    "\n",
    "To do this, we combine together the two libraries we've encountered in this session: `pandas` and `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy version\n",
    "\n",
    "We want to parse all EpiDoc files contained in `data/` and extract all names (`<name>`). \n",
    "\n",
    "For each name we retain the following information:\n",
    "- surface form (the textual content of the XML element)\n",
    "- identifier (contained in `@nymRef`)\n",
    "- type (contained in `@type`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid that the notebook becomes too messy, each step of the program is wrapped into a function.\n",
    "\n",
    "These are the functions we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about this, it's just to add the type hints\n",
    "# to each function declaration\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fetch_input_filenames(data_folder):\n",
    "    # let's get the path of XML files\n",
    "    # we filter only files with XML extension\n",
    "    # it can be useful to ignore e.g. `.DS_Store` files (under MacOS)\n",
    "\n",
    "    return [\n",
    "        os.path.join(data_folder, file)\n",
    "        for file in os.listdir(data_folder)\n",
    "        if \".xml\" in file\n",
    "    ]\n",
    "\n",
    "def read_xml(path) -> BeautifulSoup:\n",
    "    \"\"\"Reads the input XML file into a `BeautifulSoup` document.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as inpfile:\n",
    "        return BeautifulSoup(inpfile)\n",
    "    \n",
    "def find_name_element(doc: BeautifulSoup) -> List:\n",
    "    \"\"\"Extracts all `<name>` elements from an XML document.\"\"\"\n",
    "    return doc.find_all('name')\n",
    "\n",
    "\n",
    "def parse_name_element(element: bs4.element.Tag) -> dict:\n",
    "    \"\"\"Transforms a `<name>` element into a dictionary.\"\"\"\n",
    "    assert element.name == 'name'\n",
    "    return {\n",
    "        \"surface\": element.text,\n",
    "        \"id\": element.get('nymref'),\n",
    "        \"type\": element.get('type')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are ready to do the following:\n",
    "- we iterate through all the files in the directory `data/*.xml` (`line 3`)\n",
    "- for each file, we iterate through its `<name>` element\n",
    "- for each of these elements, we parse some information out of it and store it in a dictionary\n",
    "- finally, all these new dictionaries are stored in a list.\n",
    "\n",
    "This type of syntax construct in Python is called **list comprehension**. It's very powerful (yet a bit scary at first) as it allows for writing complex sequences of processing steps in a very compact fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    parse_name_element(name)\n",
    "    for file in fetch_input_filenames('data/')\n",
    "    for name in find_name_element(read_xml(file))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.DataFrame(names).set_index('id', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced version\n",
    "\n",
    "We want to extract all names from the TEI files while keeping the provenance of each name (i.e. the path of the file where it was found)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic is the same as in the code above, except for `line 2`. Instead of throwing all the names together, we create a tuple containing as the first element the file path, and as the second element the list of names it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    (file, parse_name_element(name))\n",
    "    for file in fetch_input_filenames('data/')\n",
    "    for name in find_name_element(read_xml(file))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we need to *inject* the filename information into each name, before creating the dataframe.\n",
    "\n",
    "We do this in two steps:\n",
    "1. we create a list of dataframes, one per file (containing all names + the file path)\n",
    "2. we concatenate all the dataframes in the list into a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for file, name_elements in names:\n",
    "    df = pd.DataFrame([name_elements]).set_index('id', drop=False)\n",
    "    df['file'] = file\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's see now how `pandas` can be used to explore this data. \n",
    "\n",
    "Think of `pandas` like a very powerful spreadsheet software, that you can program yourself to answer your burning questions about any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many names do we have for each type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Do you notice anything special about the counts above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times does each name occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very informative, but we can even plot the name frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.id.value_counts().plot(kind='bar', figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequently occurring\n",
    "names_df.id.value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least frequently occurring\n",
    "names_df.id.value_counts().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All name surface forms are quite unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.surface.value_counts().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at names ids, we can see that in average each name occur roughly 1.2 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.id.value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.id.value_counts().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And 75% of the names occur only once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "\n",
    "- You are asked to write a simple python program by modifying the code we provided in notebook `Pandas_BeautifulSoup.ipynb`, section \"XML data → `DataFrame`\"; the current code looks for `<name>` element and creates a `DataFrame` out of it. For the exercise you are asked to do something similar, but for a different set of TEI/EpiDoc elements of your choice.\n",
    "- These are the steps to follow:\n",
    "    1)  to identify one or more TEI elements of interest (can be lemmata, variants, bibliographic elements, metadata, etc.); \n",
    "    2)  to specify what information you to retain from them, and extract it from the XML (via `BeautifulSoup`) by modifying the code provided;\n",
    "    3) convert it to a `pandas.DataFrame` and explore some statistics (for example by using `value_counts()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
